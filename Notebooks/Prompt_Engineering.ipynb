{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Configurar entorno de Trabajo.\n",
        "\n"
      ],
      "metadata": {
        "id": "TrbmPQ4lwlpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Local - MV.\n",
        "Si se trabaja en un entorno local o una m√°quina virtual lo ideal es crear un entorno virtual.\n",
        "```Python\n",
        "# Crea un nuevo entorno virtual llamado 'mi_entorno' con Python 3.9\n",
        "!conda create -n mi_entorno python=3.9\n",
        "\n",
        "# Activa el entorno virtual (Linux/macOS)\n",
        "!conda activate mi_entorno\n",
        "\n",
        "# Instala paquetes dentro del entorno virtual\n",
        "!conda install -n mi_entorno <nombre_del_paquete>\n",
        "\n",
        "# Desactiva el entorno virtual\n",
        "```"
      ],
      "metadata": {
        "id": "MMD3xW7nylAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Google colab\n",
        "\n",
        "```Python\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# setear Directorio\n",
        "path = \"/content/drive/MyDrive/genai/PromptEngineering\"\n",
        "%cd {path}\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "s8W4aH5ezTej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5RmlaR9zSda",
        "outputId": "7b7b3ef0-933c-4863-d97e-700304d36f4c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/genai/PromptEngineering\"\n",
        "%cd {path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3faYpgbzuw_",
        "outputId": "4fcf8fe7-7c36-4bf5-a957-51806a708385"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/genai/PromptEngineering\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Utilizar el API de chatGPT\n",
        "\n",
        "- Para utilizar el API, necesitamos crear un cuenta en [OpenAI](https://platform.openai.com/docs/overview) y luego ingresar a este [link](https://platform.openai.com/api-keys) para conseguir tus creenciales.\n",
        "- Una vez obtenidas o creadas las credenciales, configurarlos, de manera que lo podamos utilizar para conectarse al modelo.\n",
        "```Python\n",
        "# nano .env\n",
        "OPENAI_API_KEY = \"xxxxxxxxxxxx\"\n",
        "CTRL+O\n",
        "ENTER\n",
        "CTRL+X\n",
        "```"
      ],
      "metadata": {
        "id": "NLGQPTfF0viR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!touch .env\n",
        "# Escribe en el archivo .env\n",
        "#with open(\".env\", \"w\") as f:\n",
        "#  f.write(\"OPENAI_API_KEY = \\\"TU_CLAVE_API\\\"\\n\")"
      ],
      "metadata": {
        "id": "l_UyUOZo_DKE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install python-dotenv\n",
        "#!pip install openai\n",
        "#!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tx8_5ndAMDc",
        "outputId": "074b9d49-91fe-4825-bd92-8024b773c87f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar credenciales\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv() # take environment variables from .env.\n",
        "# Set your OpenAI key as an environment variable\n",
        "# https://platform.openai.com/api-keys\n",
        "from openai import OpenAI\n",
        "import os\n",
        "client = OpenAI(\n",
        "api_key=os.environ['OPENAI_API_KEY'], # Default\n",
        ")\n"
      ],
      "metadata": {
        "id": "4WJmqvqa_t6F"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(prompt):\n",
        "    \"\"\"\n",
        "    Esta funci√≥n env√≠a un mensaje a un modelo de lenguaje de OpenAI (gpt-3.5-turbo)\n",
        "    y obtiene una respuesta basada en el prompt proporcionado por el usuario.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create( # metodo utilizado\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a helpful assistant.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "        }\n",
        "    ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "Yb64zkc5AGsH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos nuestro prompt\n",
        "prompt = \"\"\"\n",
        "Cual es la capital de Colombia?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "OPMn6A8nF0Ou"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Proceso interno\n",
        "- El modelo recibe el mensaje del sistema: \"You are a helpful assistant.\".  \n",
        "- Luego, recibe el mensaje del usuario: \"Cual es la capital de Colombia?\".\n",
        "- Genera una respuesta como: \"La capital de Colombia es Bogot√°. üåÜ Es la ciudad m√°s grande del pa√≠s y su centro pol√≠tico, econ√≥mico\"."
      ],
      "metadata": {
        "id": "6IVJoxCjGxUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preguntamos al modelo\n",
        "get_response(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lnhUSIcfGYbE",
        "outputId": "f20627c9-31cf-4e2c-9f0d-576903c5c139"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'La capital de Colombia es Bogot√°.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar la cantidad de tokens de entrada y salida\n",
        "# Gemini: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/get-token-count\n",
        "# 1. Import the package:\n",
        "import tiktoken\n",
        "# 2. Load an encoding with tiktoken.get_encoding()\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\")"
      ],
      "metadata": {
        "id": "IIj3vUGwHPPb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tokens(text_string: str, encoding_name: str) -> int:\n",
        "    \"\"\"\n",
        "    Returns the number of tokens in a text string using a given encoding.\n",
        "    Args:\n",
        "    text: The text string to be tokenized.\n",
        "    encoding_name: The name of the encoding to be used for tokenization.\n",
        "    Returns:\n",
        "    The number of tokens in the text string.\n",
        "    Raises:\n",
        "    ValueError: If the encoding name is not recognized.\n",
        "    \"\"\"\n",
        "    encoding = tiktoken.get_encoding(encoding_name)\n",
        "    num_tokens = len(encoding.encode(text_string))\n",
        "    return num_tokens\n"
      ],
      "metadata": {
        "id": "85Gi2ULPIz7M"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Use the function to count the number of tokens in a text string.\n",
        "print(count_tokens(prompt, \"cl100k_base\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dcpFnZhK66I",
        "outputId": "e0a15794-b82b-4b84-cff2-ef854ab4ec51"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "allpromt = \"\"\"You are a helpful assistant.\n",
        "Cual es la capital de Colombia?\"\"\"\n",
        "print(count_tokens(allpromt, \"cl100k_base\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS0WZ5AOLDJC",
        "outputId": "402bff7f-41d3-47eb-95fa-1a8332fa0783"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "flF6g4M0Lngw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}